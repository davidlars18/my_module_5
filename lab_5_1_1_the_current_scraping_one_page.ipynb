{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study - The Current\n",
    "\n",
    "* The Current is an alternative radio station\n",
    "* We will pull information about the play list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0 - Inspect the following page\n",
    "\n",
    "* Song title\n",
    "* Artist\n",
    "* Play time\n",
    "* Day, date, period (am/pm)\n",
    "\n",
    "http://www.thecurrent.org/playlist/2014-01-01/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import modules here\n",
    "from composablesoup import find, find_all, get_text, has_attr\n",
    "from composable.sequence import slice, head\n",
    "from composable.strict import map, filter\n",
    "from composable.string import replace, split\n",
    "from composable import pipeable\n",
    "from composable import from_toolz as tlz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in the page here\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "s = requests.Session()\n",
    "r = s.get('https://www.thecurrent.org/playlist/2014-10-14/01')\n",
    "music_page = BeautifulSoup(r.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Pull off the period of the day (am/pm)\n",
    "\n",
    "Pull out the \"am\"/\"pm\"\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Search the soup\n",
    "    1. There should be one item returned\n",
    "4. Use soup\\string methods to pull out the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "strip = pipeable(lambda s: s.strip())\n",
    "(music_page\n",
    " >> find('span', attrs = {'class':'hour-header'})\n",
    " >> get_text\n",
    " >> strip\n",
    " >> split(' ')\n",
    " >> tlz.get(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_period = pipeable( lambda soup: soup\n",
    " >> find('span', attrs = {'class':'hour-header'})\n",
    " >> get_text\n",
    " >> strip\n",
    " >> split(' ')\n",
    " >> tlz.get(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "music_page >> get_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Pull off DJ\n",
    "\n",
    "Use a similar process to pull off the DJ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Jade'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "remove_dj = pipeable(lambda s: s.replace('DJ: ',''))\n",
    "(music_page\n",
    " >> find('h5', attrs = {'class':'currentDj'})\n",
    " >> get_text\n",
    " >> remove_dj\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_dj = pipeable(lambda soup: soup\n",
    " >> find('h5', attrs = {'class':'currentDj'})\n",
    " >> get_text\n",
    " >> remove_dj\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Jade'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "music_page >> get_dj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Pull out the day of the week\n",
    "\n",
    "* Pull out the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Tuesday'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "(\n",
    "    music_page\n",
    "    >> (find('a', attrs={'class':'start-picker'}))\n",
    "    >> get_text\n",
    "    >> split(',')\n",
    "    >> tlz.get(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_day = pipeable(lambda soup: soup\n",
    "    >> (find('a', attrs={'class':'start-picker'}))\n",
    "    >> get_text\n",
    "    >> split(',')\n",
    "    >> tlz.get(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Tuesday'"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "music_page >> get_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title of each song\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Use `find_all` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Write a function to pull out the title\n",
    "6. Write a single pipe to convert the original soup into a list of titles. \n",
    "7. Verify you have the right number of titles.\n",
    "8. Package the pipe in a function named `get_title`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Kill The Fun',\n",
       " 'Artifact #1',\n",
       " 'Gooey',\n",
       " 'The Puritan',\n",
       " \"You're All I've Got Tonight\",\n",
       " 'No One Is Lost',\n",
       " 'Moon When the Cherries Turn Black',\n",
       " 'Colorado',\n",
       " 'Never, Never Gonna Give You Up',\n",
       " 'Trainwreck 1979',\n",
       " 'My Girls',\n",
       " 'BOYTROUBLE feat. Lizzo',\n",
       " 'White Lies',\n",
       " 'Beware the Dog',\n",
       " 'Knock Me Down']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "(music_page\n",
    "    >> find_all('h5', attrs={'class':'title'})\n",
    "    >> map(get_text)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_title = pipeable(lambda soup: soup\n",
    "    >> find_all('h5', attrs={'class':'title'})\n",
    "    >> map(get_text)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Kill The Fun',\n",
       " 'Artifact #1',\n",
       " 'Gooey',\n",
       " 'The Puritan',\n",
       " \"You're All I've Got Tonight\",\n",
       " 'No One Is Lost',\n",
       " 'Moon When the Cherries Turn Black',\n",
       " 'Colorado',\n",
       " 'Never, Never Gonna Give You Up',\n",
       " 'Trainwreck 1979',\n",
       " 'My Girls',\n",
       " 'BOYTROUBLE feat. Lizzo',\n",
       " 'White Lies',\n",
       " 'Beware the Dog',\n",
       " 'Knock Me Down']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "music_page >> get_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull off the name of the artist\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Use `find_all` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Write a function to pull out the artist\n",
    "6. Write a single pipe to convert the original soup into a list of artists. \n",
    "7. Verify you have the right number of artists.\n",
    "8. Package the pipe in a function named `get_artist`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Haley Bonar',\n",
       " 'Conor Oberst',\n",
       " 'Glass Animals',\n",
       " 'Blur',\n",
       " 'The Cars',\n",
       " 'Stars',\n",
       " 'The Pines',\n",
       " 'Chastity Brown',\n",
       " 'Barry White',\n",
       " 'Death From Above 1979',\n",
       " 'Animal Collective',\n",
       " 'Prince and 3RDEYEGIRL',\n",
       " 'Max Frost',\n",
       " 'The Griswolds',\n",
       " 'Red Hot Chili Peppers']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "(\n",
    "    music_page\n",
    "    >> find_all('h5', attrs={'class':'artist'})\n",
    "    >> map(get_text)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_artist = pipeable(lambda soup: soup\n",
    "    >> find_all('h5', attrs={'class':'artist'})\n",
    "    >> map(get_text)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Haley Bonar',\n",
       " 'Conor Oberst',\n",
       " 'Glass Animals',\n",
       " 'Blur',\n",
       " 'The Cars',\n",
       " 'Stars',\n",
       " 'The Pines',\n",
       " 'Chastity Brown',\n",
       " 'Barry White',\n",
       " 'Death From Above 1979',\n",
       " 'Animal Collective',\n",
       " 'Prince and 3RDEYEGIRL',\n",
       " 'Max Frost',\n",
       " 'The Griswolds',\n",
       " 'Red Hot Chili Peppers']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "music_page >> get_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}